{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3228288c",
   "metadata": {},
   "source": [
    "# $\\color{black}{}$\n",
    "### 3. Machine Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16990b",
   "metadata": {},
   "source": [
    "There are two main classes of machine learning:\n",
    "1. __Supervised__ This is where you learn about the relationship between some measurement of the data and some label of the data. Once the relationship is established, you can then use it to predict what label to apply to new measurements. Supervised learning falls into two categories:\n",
    "  - __classification__ where the labels are discrete. For example identifying the species of a flower from some measurements of its petals.\n",
    "  - __regression__ where the labels are continuous. For example estimating the price of a house based on its number of rooms, size of garden etc.\n",
    "2. __Unsupervised__ This is where you don't have any label associated with the data and the algorithm will need to extract features of interest itself. Examples of this are:\n",
    "  - __clustering__\n",
    "  - __dimensionality reduction__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8f975",
   "metadata": {},
   "source": [
    "__The supervised learning process__\n",
    "\n",
    "---\n",
    "\n",
    "![title](https://milliams.com/courses/applied_data_analysis/ml_workflow.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5af47",
   "metadata": {},
   "source": [
    "Once you have collected your data, you need to choose which model best represents the relationship between __*X*__ and __*y*__. Perhaps a linear regression is sufficient or maybe you need something more complex. There is no magic solution to knowing which model to use, it comes from experience and experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b549131",
   "metadata": {},
   "source": [
    "Using __*X*__ and __*y*__ we train (or \"fit\") our model to predict the relationship between those two (making sure to split them into *train* and *test* subsets to validate our model). After this point the parameters of our model are fixed and can be detached from the data that were used to train it. It is now a \"black box\" which can make predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
